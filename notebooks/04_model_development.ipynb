{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction - Model Development and Evaluation\n",
    "\n",
    "This notebook implements and evaluates various machine learning models for predicting customer churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Add the src directory to the path to import custom modules\n",
    "sys.path.append('../')\n",
    "from src.models.model_training import (\n",
    "    train_logistic_regression,\n",
    "    train_random_forest,\n",
    "    train_xgboost,\n",
    "    train_lightgbm,\n",
    "    train_svm,\n",
    "    handle_class_imbalance,\n",
    "    save_model,\n",
    "    load_model\n",
    ")\n",
    "from src.evaluation.model_evaluation import (\n",
    "    calculate_metrics,\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc_curve,\n",
    "    plot_precision_recall_curve,\n",
    "    compare_models,\n",
    "    calculate_business_impact\n",
    ")\n",
    "\n",
    "# Set up plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define file paths\n",
    "ENGINEERED_DATA_PATH = '../data/processed/churn_engineered.csv'\n",
    "SCALED_DATA_PATH = '../data/processed/churn_scaled.csv'\n",
    "MODELS_DIR = '../models/'\n",
    "FEATURE_SETS_PATH = '../models/feature_sets.json'\n",
    "\n",
    "# Load the engineered data\n",
    "df_engineered = pd.read_csv(ENGINEERED_DATA_PATH)\n",
    "print(f\"Engineered dataset shape: {df_engineered.shape}\")\n",
    "df_engineered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the scaled data\n",
    "df_scaled = pd.read_csv(SCALED_DATA_PATH)\n",
    "print(f\"Scaled dataset shape: {df_scaled.shape}\")\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load feature sets\n",
    "with open(FEATURE_SETS_PATH, 'r') as f:\n",
    "    feature_sets = json.load(f)\n",
    "\n",
    "print(\"Available feature sets:\")\n",
    "for feature_set_name, features in feature_sets.items():\n",
    "    print(f\"{feature_set_name}: {len(features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Splitting and Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check class distribution\n",
    "print(\"Target variable distribution:\")\n",
    "print(df_engineered['Exited'].value_counts())\n",
    "print(\"\\nPercentage:\")\n",
    "print(df_engineered['Exited'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to prepare data for modeling\n",
    "def prepare_data(df, feature_set_name, handle_imbalance=None, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data for modeling by splitting into train/test sets and handling class imbalance.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the data\n",
    "        feature_set_name: Name of the feature set to use\n",
    "        handle_imbalance: Method to handle class imbalance ('smote', 'random_over', 'random_under', None)\n",
    "        test_size: Proportion of data to use for testing\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Select features and target\n",
    "    features = feature_sets[feature_set_name]\n",
    "    X = df[features]\n",
    "    y = df['Exited']\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Handle class imbalance if specified\n",
    "    if handle_imbalance == 'smote':\n",
    "        smote = SMOTE(random_state=random_state)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    elif handle_imbalance == 'random_over':\n",
    "        over_sampler = RandomOverSampler(random_state=random_state)\n",
    "        X_train, y_train = over_sampler.fit_resample(X_train, y_train)\n",
    "    elif handle_imbalance == 'random_under':\n",
    "        under_sampler = RandomUnderSampler(random_state=random_state)\n",
    "        X_train, y_train = under_sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Testing set shape: {X_test.shape}\")\n",
    "    print(f\"Training set class distribution:\\n{pd.Series(y_train).value_counts()}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare data for modeling using the selected feature set\n",
    "feature_set_name = 'selected_top'  # Using the combined top features from feature selection\n",
    "X_train, X_test, y_train, y_test = prepare_data(\n",
    "    df_engineered, feature_set_name, handle_imbalance='smote', test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train logistic regression model\n",
    "lr_model = train_logistic_regression(X_train, y_train, class_weight='balanced')\n",
    "\n",
    "# Make predictions\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_prob = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "lr_metrics = calculate_metrics(y_test, lr_pred, lr_prob)\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "for metric, value in lr_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(y_test, lr_pred)\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(y_test, lr_prob)\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "save_model(lr_model, os.path.join(MODELS_DIR, 'logistic_regression.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze feature importance for logistic regression\n",
    "lr_coef = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': lr_model.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=lr_coef)\n",
    "plt.title('Logistic Regression Coefficients', fontsize=15)\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.axvline(x=0, color='black', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train random forest model\n",
    "rf_model = train_random_forest(X_train, y_train, n_estimators=100, max_depth=10, class_weight='balanced')\n",
    "\n",
    "# Make predictions\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "rf_metrics = calculate_metrics(y_test, rf_pred, rf_prob)\n",
    "print(\"Random Forest Metrics:\")\n",
    "for metric, value in rf_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(y_test, rf_pred)\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(y_test, rf_prob)\n",
    "plt.title('Random Forest ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "save_model(rf_model, os.path.join(MODELS_DIR, 'random_forest.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze feature importance for random forest\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=rf_importance.head(15))\n",
    "plt.title('Random Forest Feature Importance (Top 15)', fontsize=15)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train XGBoost model\n",
    "xgb_model = train_xgboost(X_train, y_train, n_estimators=100, max_depth=5, learning_rate=0.1, scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]))\n",
    "\n",
    "# Make predictions\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "xgb_metrics = calculate_metrics(y_test, xgb_pred, xgb_prob)\n",
    "print(\"XGBoost Metrics:\")\n",
    "for metric, value in xgb_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(y_test, xgb_pred)\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(y_test, xgb_prob)\n",
    "plt.title('XGBoost ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "save_model(xgb_model, os.path.join(MODELS_DIR, 'xgboost.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze feature importance for XGBoost\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=xgb_importance.head(15))\n",
    "plt.title('XGBoost Feature Importance (Top 15)', fontsize=15)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train LightGBM model\n",
    "lgb_model = train_lightgbm(X_train, y_train, n_estimators=100, max_depth=5, learning_rate=0.1, class_weight='balanced')\n",
    "\n",
    "# Make predictions\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "lgb_prob = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "lgb_metrics = calculate_metrics(y_test, lgb_pred, lgb_prob)\n",
    "print(\"LightGBM Metrics:\")\n",
    "for metric, value in lgb_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(y_test, lgb_pred)\n",
    "plt.title('LightGBM Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(y_test, lgb_prob)\n",
    "plt.title('LightGBM ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "save_model(lgb_model, os.path.join(MODELS_DIR, 'lightgbm.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze feature importance for LightGBM\n",
    "lgb_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': lgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=lgb_importance.head(15))\n",
    "plt.title('LightGBM Feature Importance (Top 15)', fontsize=15)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train SVM model\n",
    "svm_model = train_svm(X_train, y_train, kernel='rbf', C=1.0, gamma='scale', class_weight='balanced')\n",
    "\n",
    "# Make predictions\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "svm_prob = svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "svm_metrics = calculate_metrics(y_test, svm_pred, svm_prob)\n",
    "print(\"SVM Metrics:\")\n",
    "for metric, value in svm_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(y_test, svm_pred)\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(y_test, svm_prob)\n",
    "plt.title('SVM ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "save_model(svm_model, os.path.join(MODELS_DIR, 'svm.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train neural network model\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32), \n",
    "    activation='relu', \n",
    "    solver='adam', \n",
    "    alpha=0.0001,\n",
    "    batch_s
(Content truncated due to size limit. Use line ranges to read in chunks)