{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction - Data Preparation\n",
    "\n",
    "This notebook implements the data cleaning and preprocessing pipeline for the customer churn prediction project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set up logging\n",
    "import logging\n",
    "import sys\n",
    "# date_strftime_format = \"%Y-%m-%y %H:%M:%S\"\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(message)s\")\n",
    "\n",
    "# Add the src directory to the path to import custom modules\n",
    "sys.path.append('../')\n",
    "from src.data.data_processing import load_data, save_processed_data\n",
    "\n",
    "# Set up plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "RAW_DATA_PATH = '../data/raw/churn.csv'\n",
    "PROCESSED_DATA_PATH = '../data/processed/churn_processed.csv'\n",
    "CLEANED_DATA_PATH = '../data/cleaned/churn_cleaned.csv'\n",
    "\n",
    "# Load the data\n",
    "df = load_data(RAW_DATA_PATH)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check summary statistics\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target distribution\n",
    "print(\"Target distribution:\")\n",
    "print(df['Exited'].value_counts())\n",
    "print(\"\\nPercentage:\")\n",
    "print(df['Exited'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check categorical variables\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns:\")\n",
    "print(categorical_cols)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col} value counts:\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "df_cleaned = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "print(f\"Cleaned dataset shape: {df_cleaned.shape}\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicate_count = df_cleaned.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    df_cleaned = df_cleaned.drop_duplicates()\n",
    "    print(f\"Shape after removing duplicates: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in numerical columns\n",
    "numerical_cols = df_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_cols = [col for col in numerical_cols if col != 'Exited']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    sns.boxplot(x=df_cleaned[col])\n",
    "    plt.title(col)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers if necessary (using IQR method)\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = ((df[column] < lower_bound) | (df[column] > upper_bound)).sum()\n",
    "    print(f\"{column}: {outliers} outliers detected\")\n",
    "    \n",
    "    # Cap outliers instead of removing them\n",
    "    if outliers > 0:\n",
    "        df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
    "        df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Apply outlier handling to numerical columns\n",
    "for col in numerical_cols:\n",
    "    df_cleaned = handle_outliers(df_cleaned, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "df_processed = pd.get_dummies(df_cleaned, columns=['Geography', 'Gender'], drop_first=True) # we drop the first category to avoid dummy variable trap\n",
    "print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary columns to proper format\n",
    "binary_cols = ['HasCrCard', 'IsActiveMember']\n",
    "for col in binary_cols:\n",
    "    df_processed[col] = df_processed[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df_processed.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data\n",
    "save_processed_data(df_cleaned, CLEANED_DATA_PATH)\n",
    "print(f\"Cleaned data saved to {CLEANED_DATA_PATH}\")\n",
    "\n",
    "# Save the processed data\n",
    "save_processed_data(df_processed, PROCESSED_DATA_PATH)\n",
    "print(f\"Processed data saved to {PROCESSED_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data dictionary\n",
    "data_dictionary = {\n",
    "    'CreditScore': 'Credit score of the customer',\n",
    "    'Geography': 'Customer\\'s location (France, Spain, Germany)',\n",
    "    'Gender': 'Customer\\'s gender (Male, Female)',\n",
    "    'Age': 'Customer\\'s age in years',\n",
    "    'Tenure': 'Number of years the customer has been a client of the bank',\n",
    "    'Balance': 'Account balance',\n",
    "    'NumOfProducts': 'Number of bank products the customer uses',\n",
    "    'HasCrCard': 'Whether the customer has a credit card (1=Yes, 0=No)',\n",
    "    'IsActiveMember': 'Whether the customer is an active member (1=Yes, 0=No)',\n",
    "    'EstimatedSalary': 'Estimated salary of the customer',\n",
    "    'Exited': 'Whether the customer has churned (1=Yes, 0=No)',\n",
    "    'Geography_Germany': 'Whether the customer is from Germany (1=Yes, 0=No)',\n",
    "    'Geography_Spain': 'Whether the customer is from Spain (1=Yes, 0=No)',\n",
    "    'Gender_Male': 'Whether the customer is male (1=Yes, 0=No)'\n",
    "}\n",
    "\n",
    "# Display the data dictionary\n",
    "pd.DataFrame(list(data_dictionary.items()), columns=['Feature', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data dictionary\n",
    "data_dict_df = pd.DataFrame(list(data_dictionary.items()), columns=['Feature', 'Description'])\n",
    "output_path = '../docs/data_dictionary.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "data_dict_df.to_csv(output_path, index=False)\n",
    "print(\"Data dictionary saved to ../docs/data_dictionary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "1. Loaded the bank customer churn dataset\n",
    "2. Explored the data structure and identified key characteristics\n",
    "3. Cleaned the data by removing unnecessary columns and handling outliers\n",
    "4. Preprocessed the data by encoding categorical variables\n",
    "5. Saved the cleaned and processed datasets\n",
    "6. Created and saved a data dictionary\n",
    "\n",
    "The dataset is now ready for exploratory data analysis and feature engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
